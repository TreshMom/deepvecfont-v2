# DeepVecFont v2.1

Это fork DeepVecFont-v2. \
## Было проведенно несколько эксприрементов.

1. Классическая loss_cmd заменена на nn.CrossEntropyLoss.
2. В папке hipotez утилита по подсчету количества команд и последовательности команд у каждой буквы сгенерируемой моделью + графики, а так же примеры как можно xml парсить чтобы точечно просматривать результаты. 
Файлы типа : 200_4_new_loss.html - результат при весах на 200 эпохах, при ref_nshot = 4 и новой лосс функции.
3. Добавил комментарии по работе модели + данная версия модели переписана под то, чтобы в нее подавался один шрифт с двумя версиями Italic и Regular, но выбиралось ref_nshot из прямых и сгенерированое моделью сравнивалось с Italic. (Такую версию модели не обучал)
4. Dataloader переписан под загрузку Regular + Italic 
5. Graphic.ipynb утилитка для просмотра того, что подается в модель в npy формате
6. Probably.ipynb - мои тесты и прокидывание всего чего можно в модель 

Результат: Значительных изменений не было увидено.

## Что хотелось бы попробовать, но не попробовал?
1. Хотелось бы переписать модель под то, что бы ref_class был Regular font, а trg_class был Italic font.
Пример: Модель смотрит на класс "А" - что-то генерирует и сравнивает с Italic "А"
2. Поменять loss функции  
3. Облегчить датасет, начать не с генерации всех 52 символов - уменьшить количество классов и уменьшить группу выборку шрифтов (например только тонкие или только толстые).
Удалось выявить 4 группы на которые можно разделить 52 символа из английского алфавита: Прямые, Округлые, Смешанные, Диагональные.
4. Работать с датасетом TT 
5. Дообучение работает неправильно, кмк, будьте осторожны 

## Логический вывод: 
Кажется, что можно обучить модель на паре Regular - Italic на "тепличном" датасете с измененными loss функциями под наши задачи, а это 
1. Точное количество команд (т к при наклоне оно не меняется)
2. Последовательность команд (т к при наклоне она не менятся)