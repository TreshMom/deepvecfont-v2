{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с .npy форматом, загрузка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import SVGDataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def set_range(X):\n",
    "    return 1. - X\n",
    "\n",
    "SetRange = T.Lambda(set_range)  # convert [0, 1] -> [0, 1]\n",
    "transform = T.Compose([SetRange])\n",
    "dataset = SVGDataset(\"root\", 64, 'eng', 52, 51, 12, transform, 'train')\n",
    "\n",
    "class_data = dataset[0]['seq_len'] # чтобы обратиться по ключу надо взять 0 индекс\n",
    "\n",
    "dataloader = data.DataLoader(dataset, 1, shuffle= 'train', num_workers=0) # торчовская функция \n",
    "\n",
    "for idx, data in enumerate(dataloader):\n",
    "    for key, value in data.items():\n",
    "        print(f\"Key: {key}, Shape: {value.shape}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#print(data['sequence'])\n",
    "#print(data['sequence'].shape)\n",
    "input_sequence = data['sequence']\n",
    "input_pts_aux = data['pts_aux']\n",
    "def numericalize(cmd, n=128):\n",
    "    \"\"\"NOTE: shall only be called after normalization\"\"\"\n",
    "    # assert np.max(cmd.origin) <= 1.0 and np.min(cmd.origin) >= -1.0 \n",
    "    cmd = (cmd / 30 * n).round().clip(min=0, max=n-1).int()\n",
    "    return cmd\n",
    "arg_quant = numericalize(input_sequence[:, :, :, 4:])\n",
    "cmd_cls = torch.argmax(input_sequence[:, :, :, :4], dim=-1).unsqueeze(-1)\n",
    "input_sequence = torch.cat([cmd_cls, arg_quant], dim=-1)\n",
    "\n",
    "print(input_pts_aux[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = data['rendered']\n",
    "ref_cls = torch.randint(0, 52, (1, 4))\n",
    "trg_cls = torch.randint(0, 52, (1, 1))\n",
    "\n",
    "\"\"\"\n",
    "selected_cls = trg_cls\n",
    "selected_cls_ = selected_cls.unsqueeze(2)\n",
    "selected_cls_ = selected_cls_.unsqueeze(3)\n",
    "print(selected_cls_)\n",
    "selected_cls_ = selected_cls_.expand(1, 4, 64, 64)\n",
    "selected_img = torch.gather(input_image, 1, selected_cls_)\n",
    "print(selected_img[0][0][0])\n",
    "\"\"\"\n",
    "\n",
    "def select_imgs(images_of_onefont, selected_cls):\n",
    "    # given selected char classes, return selected imgs\n",
    "    # images_of_onefont: [bs, 52, opts.img_size, opts.img_size]\n",
    "    # selected_cls: [bs, nshot]\n",
    "    nums = selected_cls.size(1)\n",
    "    selected_cls_ = selected_cls.unsqueeze(2)\n",
    "    selected_cls_ = selected_cls_.unsqueeze(3)\n",
    "    selected_cls_ = selected_cls_.expand(images_of_onefont.size(0), nums, 64, 64)         \n",
    "    selected_img = torch.gather(images_of_onefont, 1, selected_cls_)\n",
    "    return selected_img\n",
    "\n",
    "ref_img = select_imgs(input_image, ref_cls)\n",
    "trg_img = select_imgs(input_image, trg_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "def select_seqs(seqs_of_onefont, selected_cls, opts, seq_dim):\n",
    "\n",
    "    nums = selected_cls.size(1)\n",
    "    selected_cls_ = selected_cls.unsqueeze(2)\n",
    "    selected_cls_ = selected_cls_.unsqueeze(3)\n",
    "    selected_cls_ = selected_cls_.expand(seqs_of_onefont.size(0), nums, opts.max_seq_len, seq_dim) \n",
    "    selected_seqs = torch.gather(seqs_of_onefont, 1, selected_cls_)\n",
    "    return selected_seqs\n",
    "\"\"\"\n",
    "\n",
    "def select_seqs(seqs_of_onefont, selected_cls, n):\n",
    "    nums = selected_cls.size(1)\n",
    "    selected_cls_ = selected_cls.unsqueeze(2)\n",
    "    selected_cls_ = selected_cls_.unsqueeze(3)\n",
    "    selected_cls_ = selected_cls_.expand(seqs_of_onefont.size(0), nums, 51, n) \n",
    "    selected_seqs = torch.gather(seqs_of_onefont, 1, selected_cls_)\n",
    "    return selected_seqs\n",
    "\n",
    "print(select_seqs(input_sequence, trg_cls, 9))\n",
    "print(select_seqs(input_sequence, trg_cls, 9).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_seq = select_seqs(input_sequence, trg_cls, 9) \n",
    "trg_seq = trg_seq.squeeze(1)\n",
    "\n",
    "ref_seq = select_seqs(input_sequence, ref_cls, 9) \n",
    "print(trg_seq)\n",
    "print(ref_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_pts_aux = select_seqs(input_pts_aux, trg_cls, 6)\n",
    "trg_pts_aux = trg_pts_aux.squeeze(1)\n",
    "print(trg_pts_aux)\n",
    "print(trg_pts_aux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_chat_onehot = F.one_hot(trg_cls, num_classes = 52).squeeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_seq = select_seqs(input_sequence, trg_cls, 9) \n",
    "trg_seq = trg_seq.squeeze(1)\n",
    "trg_seq_gt = trg_seq.clone().detach()\n",
    "trg_seq_gt = torch.cat((trg_seq_gt[:, :, :1], trg_seq_gt[:, :, 3:]), -1)\n",
    "\n",
    "trg_seq = trg_seq.transpose(0, 1)\n",
    "\n",
    "trg_seq_shifted = F.pad(trg_seq, (0, 0, 0, 0, 1, 0))[:-1, :, :]\n",
    "print(trg_seq_shifted)\n",
    "print(trg_seq_shifted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqlen = data['seq_len'] \n",
    "input_seqlen = input_seqlen + 1\n",
    "\n",
    "\n",
    "def select_seqlens(seqlens_of_onefont, selected_cls):\n",
    "\n",
    "    nums = selected_cls.size(1)\n",
    "    selected_cls_ = selected_cls.unsqueeze(2)\n",
    "    selected_cls_ = selected_cls_.expand(seqlens_of_onefont.size(0), nums, 1)     # 64, nums, 1    \n",
    "    selected_seqlens = torch.gather(seqlens_of_onefont, 1, selected_cls_)\n",
    "    return selected_seqlens\n",
    "\n",
    "ref_seqlen = select_seqlens(input_seqlen, ref_cls)\n",
    "ref_seqlen_cat = ref_seqlen.view(ref_seqlen.size(0) * ref_seqlen.size(1), ref_seqlen.size(2))\n",
    "print(ref_seqlen_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = select_imgs(input_image, ref_cls)\n",
    "trg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(ref_pad_mask)\n",
    "\"\"\"\n",
    "#ref_img # [bs, nshot, 64, 64]\n",
    "#trg_img # [bs, 1, 64, 64]\n",
    "\n",
    "\n",
    "# dim = 9, 1 command + 8 на точки\n",
    "#ref_seq # [bs, nshot, max_seq_len, dim]\n",
    "#ref_seq_cat # [max_seq_len, bs * nshot, dim]\n",
    "\n",
    "#trg_seq # [max_seq_len, bs, dim]\n",
    "#trg_seq_gt # [bs, max_seq_len, 7] dim - 2 (начальная точка = конечной предыдущей)\n",
    "#trg_seq_shifted # [max_seq_len, bs, dim]\n",
    "#trg_pts_aux # [bs, max_seq_len, 6] вспомогательные точки\n",
    "\n",
    "\n",
    "#trg_chat_onehot # [bs, onehot]\n",
    "#trg_cls # [bs, number_char] номера для trg\n",
    "#trg_seqlen # вектор длин trg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trg_seq)\n",
    "print(trg_seq_gt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Енкодер PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img\n",
    "\n",
    "img_size = 64 \n",
    "input_nc = 4\n",
    "ngf = 16\n",
    "\n",
    "n_downsampling = int(math.log(img_size, 2)) #  количество слоев свертки \n",
    "ks_list = [5] * (n_downsampling - n_downsampling // 3) + [3] * (n_downsampling // 3) # размер ядра для каждого слоя\n",
    "stride_list = [2] * n_downsampling # страйд для каждого слоя \n",
    "\n",
    "chn_mult = []\n",
    "for i in range(n_downsampling):\n",
    "    chn_mult.append(2 ** (i + 1)) # число каналов на каждом слое\n",
    "\n",
    "encoder = [nn.Conv2d(input_nc, ngf, kernel_size=7, padding=7 // 2, bias=True, padding_mode='replicate'),\n",
    "            nn.LayerNorm([ngf, 2 ** n_downsampling, 2 ** n_downsampling]),\n",
    "            nn.ReLU(True)]\n",
    "\n",
    "for i in range(n_downsampling):  # add downsampling layers\n",
    "    if i == 0:\n",
    "        chn_prev = ngf\n",
    "    else:\n",
    "        chn_prev = ngf * chn_mult[i - 1]\n",
    "    chn_next = ngf * chn_mult[i]\n",
    "\n",
    "    encoder += [nn.Conv2d(chn_prev, chn_next, kernel_size=ks_list[i], stride=stride_list[i], padding=ks_list[i] // 2, padding_mode='replicate'),\n",
    "                nn.LayerNorm([chn_next, 2 ** (n_downsampling - 1 - i), 2 ** (n_downsampling - 1 - i)]),\n",
    "                nn.ReLU(True)]\n",
    "\n",
    "encode = nn.Sequential(*encoder)\n",
    "flatten = nn.Flatten(encode) # превращение в одномерный \n",
    "\n",
    "\n",
    "print(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
